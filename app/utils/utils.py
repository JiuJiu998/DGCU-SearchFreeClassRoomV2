import json
import os
import re

from bs4 import BeautifulSoup

from app.models import ScheduleEntry
from app.utils.ParserResult import ParserResult
import base64
import time

import ddddocr

from app.config import WEB_ACCOUNT, WEB_PASSWORD
import requests
from lxml import etree


# æ­£åˆ™ä»…æå– "(xxxå‘¨)"
week_pattern = re.compile(r'\([^()]*?å‘¨\)')

SECTION_MAP = ["0102", "0304", "0506", "0708", "0910", "1112"]


def parse_weeks(weeks_str):
    """è§£æå‘¨æ¬¡å­—ç¬¦ä¸²ï¼Œè¿”å›å‘¨æ¬¡åˆ—è¡¨"""
    weeks_parse_failed_counter = 0
    cleaned = re.sub(r'[()å‘¨]', '', weeks_str)
    cleaned = cleaned.replace("å•å‘¨", "").replace("åŒå‘¨", "")
    periods = re.split(r'[,ï¼Œ]', cleaned)

    week_list = []
    for period in periods:
        period = period.strip()
        if not period:
            continue
        if '-' in period:
            try:
                start, end = map(int, period.split('-'))
                week_list.extend(range(start, end + 1))
            except:
                weeks_parse_failed_counter += 1
                continue
        elif period.isdigit():
            week_list.append(int(period))
        elif 'å•' in period or 'åŒ' in period:
            try:
                week_num = int(re.sub(r'[å•åŒ]', '', period))
                week_list.append(week_num)
            except:
                weeks_parse_failed_counter += 1
                continue
        else:
            weeks_parse_failed_counter += 1
            continue
    return sorted(set(week_list))


class ScheduleParser:
    def __init__(self, html_name):
        pass
        self.html_name = html_name
        self.results: [ScheduleEntry] = []
        self.html_results: [ParserResult] = []
        self.white_room_dict: [ParserResult] = []

    def parser_html(self):
        print("å¼€å§‹è§£æhtml")
        results: [ParserResult] = []
        # TODO: è§£æHTMLæ–‡ä»¶ä¸ºåŸºæœ¬çš„resultsç»“æœï¼Œæ­¤ç»“æœæœªæ‹“å±•å‘¨æ¬¡ã€æœªæ‹“å±•æ•™å®¤ï¼Œä¸ºåŸºæœ¬ç»“æœ
        if os.path.isfile(self.html_name):
            with open(self.html_name, 'r', encoding='utf-8') as f:
                soup = BeautifulSoup(f, 'html.parser')
        else:
            exit(f"æ‰¾ä¸åˆ°:{self.html_name}")

        table = soup.find("table")
        tbody = table.find("tbody") or table

        for rox_idx, tr in enumerate(tbody.find_all("tr")):
            tds = tr.find_all("td")

            for col_idx, td in enumerate(tds):
                blocks = td.find_all("div", class_="kbcontent1")
                if not blocks or col_idx == 0:
                    continue

                weekday = ((col_idx - 1) // 6) + 1  # ä½¿ç”¨1~7ä»£è¡¨å‘¨ä¸€åˆ°å‘¨æ—¥
                section = SECTION_MAP[(col_idx - 1) % 6]

                for block in blocks:
                    # åŸå§‹è¡Œæ•°æ®
                    raw_lines = block.get_text("\n", strip=False).split("\n")
                    # 1ã€åˆå¹¶çº¯æ ‡ç‚¹è¡Œåˆ°ä¸Šä¸€è¡Œ
                    merged_lines = []
                    for ln in raw_lines:
                        stripped = ln.strip()
                        if stripped in [",", "ï¼Œ", ";", "ï¼›"] or re.fullmatch(r'^[^\w\u4e00-\u9fff]+$', stripped):
                            if merged_lines:
                                merged_lines[-1] = merged_lines[-1].rstrip() + stripped
                            else:
                                continue
                        else:
                            merged_lines.append(ln)

                    # 2ã€æŠŠåªå«ç©ºç™½æˆ–è€…åˆ†å‰²ç¬¦å·çš„è¡Œå˜æˆ â€œ" ä»¥ä¾¿ç»Ÿä¸€åˆ¤æ–­ï¼Œé’ˆå¯¹ä¸åŒå‘¨æ¬¡ä¸åŒæ•™å®¤çš„è¯¾ç¨‹
                    lines = [ln.strip() if ln and ln.strip() != "-------" else "" for ln in merged_lines]

                    n = len(lines)

                    if n == 0:
                        continue

                    # æ‰¾å‡ºæ‰€æœ‰åŒ…å«å‘¨æ¬¡çš„è¡Œçš„ç´¢å¼•
                    week_line_idxs = [i for i, ln in enumerate(lines) if ln and week_pattern.search(ln)]
                    if not week_line_idxs:
                        continue    # æ‰€æœ‰è¡Œéƒ½æ²¡æœ‰åŒ…å«å‘¨æ¬¡çš„

                    # åˆå¹¶è¿ç»­çš„å‘¨æ¬¡ä¸ºä¸€ä¸ªç»„
                    groups = []
                    start = week_line_idxs[0]
                    prev = start
                    for idx in week_line_idxs[1:]:
                        if idx == prev + 1:
                            prev = idx
                            continue
                        else:
                            groups.append((start, prev))
                            start = idx
                            prev = idx
                    groups.append((start, prev))

                    for (g_start, g_end) in groups:
                        # æ”¶é›†è¯¥ç»„å†…æ‰€æœ‰æ‹¬å·å†…å®¹ï¼ˆæŒ‰è¡Œé¡ºåºï¼‰
                        week_list = []
                        for j in range(g_start, g_end + 1):
                            matches = week_pattern.findall(lines[j])
                            if matches:
                                week_list.extend(matches)

                        if not week_list:
                            continue

                        # 3ã€å‘åæ‰¾ room_no
                        room_no = None
                        for j in range(g_end + 1, n):
                            cand = lines[j]
                            if not cand:
                                continue
                            if week_pattern.search(cand):
                                continue
                            if re.fullmatch(r'^[^\w\u4e00-\u9fff]+$', cand):
                                continue
                            room_no = cand
                            break

                        # å›é€€ç­–ç•¥ï¼šä»æ•´ä¸ªå—ä¸­æ‰¾ç¬¬ä¸€ä¸ªåˆç†çš„éå‘¨æ¬¡è¡Œ
                        if room_no is None:
                            for cand in lines:
                                if not cand:
                                    continue
                                if week_pattern.search(cand):
                                    continue
                                if re.fullmatch(r'^[^\w\u4e00-\u9fff]+$', cand):
                                    continue
                                room_no = cand
                                break

                        if not room_no:
                            continue

                        week_text = " , ".join(week_list)

                        pr = ParserResult(
                            building=None,
                            floor=None,
                            room_no=room_no,
                            section=section,
                            week=week_text,
                            weekday=weekday,
                        )
                        results.append(pr)

        self.html_results = results
        print("è§£æç»“æœå…±è®¡:", len(self.html_results))

    def filter_white_rooms(self):
        # TODO: æ„å»ºbuildingç™½åå•ï¼Œåªä¿ç•™ç›®æ ‡buildingæ•°æ®ï¼Œå¹¶ä»room_noä¸­è§£æå‡ºbuildingå’Œfloorèµ‹å€¼
        print("å¼€å§‹æ„å»ºç™½åå•åŒºåŸŸ")
        white_room_no_dict = [
            {'area': "7å·æ¥¼AåŒº", "origin": "7å·æ¥¼A"},
            {'area': "7å·æ¥¼BåŒº", "origin": "7å·æ¥¼B"},
            {'area': "7å·æ¥¼CåŒº", "origin": "7å·æ¥¼C"},
            {'area': "ç¾½æ¯›çƒåœº", "origin": "ç»¼åˆé¦†-ç¾½æ¯›çƒåœº"}
        ]
        # æ„å»ºç™½åå•å‰ç¼€å’Œå®Œå…¨åŒ¹é…é›†åˆ
        prefix_whitelist = [w['origin'] for w in white_room_no_dict if w['origin'] != w['area']]
        exact_whitelist = [w['area'] for w in white_room_no_dict]

        # æ„å»º origin -> area çš„æ˜ å°„ï¼Œæ–¹ä¾¿èµ‹å€¼ building
        origin_area_map = {w['origin']: w['area'] for w in white_room_no_dict}
        area_exact_map = {w['area']: w['area'] for w in white_room_no_dict}
        filtered_results = []

        for result in self.html_results:
            rooms = result.room_no.split(',')
            valid_rooms = []
            for r in rooms:
                r = r.strip()
                if "-------" in r:
                    continue

                # å¦‚æœ r æ˜¯æ•°å­—æˆ–ç¼©å†™ï¼ˆä¾‹å¦‚ 113ï¼‰ï¼Œåˆ™è¡¥å…¨å‰ç¼€
                if re.match(r'^\d+$', r):
                    if valid_rooms:
                        # ç»§æ‰¿å‰ä¸€ä¸ªæˆ¿é—´å·çš„å‰ç¼€ï¼ˆå»æ‰åé¢çš„æ•°å­—éƒ¨åˆ†ï¼‰
                        prefix = re.match(r'^(.*?)[0-9]+$', valid_rooms[-1]).group(1)
                        r = prefix + r

                # æ£€æŸ¥ç™½åå•
                matched_area = None
                if any(r.startswith(p) for p in prefix_whitelist):
                    for p in prefix_whitelist:
                        if r.startswith(p):
                            matched_area = origin_area_map[p]
                            break
                elif r in exact_whitelist:
                    matched_area = area_exact_map[r]

                if matched_area:
                    valid_rooms.append(r)
                    result.building = matched_area

                    # floor è§£æï¼šABC åé¢çš„ç¬¬ä¸€ä¸ªæ•°å­—
                    m = re.match(r'.*?[ABC](\d)', r)
                    if m:
                        result.floor = int(m.group(1))
                    else:
                        result.floor = 1  # ç¾½æ¯›çƒåœºç­‰ç‰¹æ®ŠåŒºåŸŸé»˜è®¤1æ¥¼

            if valid_rooms:
                result.room_no = ','.join(valid_rooms)
                filtered_results.append(result)

        self.white_room_dict = filtered_results
        print(f"è§£æç»“æœå…±è®¡:{len(self.white_room_dict)}")

    def expand_weeks_rooms(self):
        """
        å°† ParserResult ä¸­çš„ week / room_no æ‹“å±•ä¸ºä¸€å¯¹ä¸€ç»“æœ
        ä¾‹å¦‚ï¼š
            week="(1,3å‘¨) , (5-7å‘¨)" â†’ [1,3,5,6,7]
            room_no="3B311,3B312" â†’ ["3B311", "3B312"]
        æœ€ç»ˆç”Ÿæˆ week Ã— room_no çš„é…å¯¹ç»„åˆ
        """
        print("å¼€å§‹è¿›è¡Œç¬›å¡å°”ç§¯æ‹“å±•")
        end_total_results = []

        for result in self.white_room_dict:
            # 1. æ‹“å±•å‘¨æ¬¡ â†’ å˜æˆåˆ—è¡¨
            week_list = parse_weeks(result.week)  # [1,3,5,6,7]

            # 2. æ‹†åˆ†æ•™å®¤ â†’ å˜æˆåˆ—è¡¨
            room_list = [r.strip() for r in result.room_no.split(',') if r.strip()]

            # 3. ç¬›å¡å°”ç§¯é…å¯¹
            for week in week_list:
                for room in room_list:

                    # å¦‚æœ room æ»¡è¶³ 7å·æ¥¼A101 æ ¼å¼ï¼Œåˆ™æˆªå–åä¸‰ä½æ•°å­—
                    m = re.match(r'7å·æ¥¼[ABC](\d{3})$', room)
                    if m:
                        clean_room = m.group(1)  # å–åä¸‰ä½æ•™å®¤å·
                    else:
                        clean_room = room  # ç¾½æ¯›çƒåœºç­‰ä¿æŒåŸæ ·

                    new_r = ParserResult(
                        building=result.building,
                        floor=result.floor,
                        room_no=clean_room,
                        section=result.section,
                        week=week,
                        weekday=result.weekday
                    )
                    end_total_results.append(new_r)

        # è¦†ç›–æœ€ç»ˆç»“æœ
        self.results = end_total_results
        print(f"æ‹“å±•ç»“æœå…±è®¡:{len(self.results)}")

    def export_json(self, output_path):
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump([r.to_dict() for r in self.results], f, ensure_ascii=False, indent=4)

        print(f"\nğŸ‰ å·²æˆåŠŸå†™å…¥ JSON æ–‡ä»¶ï¼š{output_path}")
        print(f"æ€»è®°å½•æ•°: {len(self.results)}")


class GetCourseTable:
    account = None
    password = None
    roomFileName = None
    baseUrl = "http://10.20.208.51/jsxsd"
    session = None
    kbFileName = None
    roomJsonSaveName = None
    tabelJsonSaveName = None
    scheduleJsonSaveName = None

    def __init__(self):
        self.account = WEB_ACCOUNT
        self.password = WEB_PASSWORD
        self.session = requests.session()
        self.cookieStr = None
        self.kbFileName = "kebiao.html"
        self.scheduleJsonSaveName = "total_schedule.json"

    def login(self):
        # TODO: ç™»å½•å¹¶è·å–cookies
        account_encoded = base64.b64encode(self.account.encode('utf-8'))
        password_encoded = base64.b64encode(self.password.encode('utf-8'))
        encoded = account_encoded.decode('utf-8') + "%%%" + password_encoded.decode('utf-8')

        # åˆå§‹åŒ–ddddocrè¯†åˆ«éªŒè¯ç 
        ocr = ddddocr.DdddOcr(show_ad=False)
        # è·å–éªŒè¯ç å›¾ç‰‡
        captchaResponse = self.session.get(self.baseUrl + "/verifycode.servlet")

        image_bytes = captchaResponse.content

        # ä½¿ç”¨ddddocrè¯†åˆ«
        captchaResult = ocr.classification(image_bytes)

        data = {
            'loginMethod': "LoginToXk",
            'userAccount': self.account,
            'userPassword': self.password,
            "RANDOMCODE": captchaResult,
            "encoded": encoded
        }

        # è¯·æ±‚ç™»å½•
        self.session.post(self.baseUrl + "/xk/LoginToXk", data=data)
        # è®¿é—®ä¸»é¡µ
        response = self.session.post(self.baseUrl + "/framework/xsMain.jsp")
        html = etree.HTML(response.text)
        # æ ¡éªŒç™»å½•ç»“æœ
        if "ä¸ªäººä¸­å¿ƒ" in response.text:
            # æˆåŠŸ,ä¿å­˜Cookieè®°å½•ä¸ªäººä¿¡æ¯
            self.cookieStr = '; '.join([f'{k}={v}' for k, v in self.session.cookies.items()])
            print("ç™»å½•æˆåŠŸ:" + self.cookieStr)
            return True, self.cookieStr
        else:
            # å¤±è´¥
            msgElem = html.xpath('//*[@id="showMsg"]')  # å®šä½é”™è¯¯åŸå› 
            # print(response.text)
            if msgElem:
                errorMsg = msgElem[0].text.strip()
            else:
                errorMsg = "æœªçŸ¥é”™è¯¯ï¼Œå¯èƒ½ä¸ºé¡µé¢ç»“æ„å˜åŒ–å¯¼è‡´æœªè¯»å–åˆ°é”™è¯¯ä¿¡æ¯"
            if "éªŒè¯ç é”™è¯¯" in msgElem or "è¯·å…ˆç™»å½•ç³»ç»Ÿ" == msgElem:
                print("é¢„æ–™ä¹‹å†…çš„å¼‚å¸¸:", msgElem)
                time.sleep(2)
                return self.login()

            return False, "è¯·å°è¯•é‡æ–°ç™»é™†æˆ–æ£€æŸ¥è´¦å·å¯†ç æ˜¯å¦æ­£ç¡®"

    def downloadKb(self):
        # TODO: ä¸‹è½½è¯¾è¡¨
        # http://10.20.208.51/jsxsd/kbcx/kbxx_kc_ifr
        print("å¼€å§‹ä¸‹è½½è¯¾è¡¨")
        downUrl = self.baseUrl + "/kbcx/kbxx_kc_ifr"
        headers = {
            'referer': 'http://jwn.ccdgut.edu.cn/jsxsd/kbcx/kbxx_xzb',
            'cookie': self.cookieStr,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.52'
        }
        response = self.session.post(url=downUrl, headers=headers)
        content = response.text  # è‡ªåŠ¨è§£ç æˆ str
        # æˆ–è€… content = response.content.decode('utf-8')

        with open(self.kbFileName, 'w', encoding='utf-8') as fp:
            fp.write(content)